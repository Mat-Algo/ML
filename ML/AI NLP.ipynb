{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54051819",
   "metadata": {},
   "source": [
    "NLP is field concerned with  the ability  of a computer  to understand, analyse, manipulate and potentially generate human language\n",
    "\n",
    "Ham or spam identification using NLP and random forest model\n",
    "\n",
    "auto complete sentence\n",
    "\n",
    "NLP is a broad umbrella that encompasses many topics. Some of them are sentiment analysis, topic modelling, text classification, sentence segmentation.\n",
    "\n",
    "NLTK - Natural Language Toolkit - The nltk toolkit is the most utilized package for handling natural language processing tasks. It is an open source library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fac0405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ebee4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94b9bfa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                          Body_text\n",
       "0   ham  I've been searching for the right words to tha...\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3   ham  Even my brother is not like to speak with me. ...\n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"SMSSpamCollection.tsv\",sep = \"\\t\",header = None)\n",
    "dataset.columns = ['Label','Body_text']\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe259ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data has 5568 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "print('Input data has {} rows and {} columns'.format(len(dataset),len(dataset.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c3482d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of 5568 rows, 746 are spam, 4822 are ham\n"
     ]
    }
   ],
   "source": [
    "#how many spam are there\n",
    "print(\"out of {} rows, {} are spam, {} are ham\".format(len(dataset),len(dataset[dataset['Label']=='spam']),len(dataset[dataset['Label']=='ham'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7515dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null is label: 0\n",
      "Number of null is text: 0\n"
     ]
    }
   ],
   "source": [
    "# identify how much missing data is there\n",
    "print(\"Number of null is label: {}\".format(dataset['Label'].isnull().sum()))\n",
    "\n",
    "print(\"Number of null is text: {}\".format(dataset['Body_text'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1945d899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing text data - cleaning up the text is necessary to highlight attributes that you are going to want your Ml\n",
    "#system to pick up on. Cleaning or preprocessing the data typically consists of a number of steps\n",
    "\n",
    "# Remove punctuation\n",
    "# Tokenization\n",
    "# Remove stopwords\n",
    "# Lemmatize/stem\n",
    "\n",
    "\n",
    "\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfa28f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Body_text</th>\n",
       "      <th>Body_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>Ive been searching for the right words to than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>Even my brother is not like to speak with me T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>As per your request Melle Melle Oru Minnaminun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>WINNER As a valued network customer you have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>Had your mobile 11 months or more U R entitled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>Im gonna be home soon and i dont want to talk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>SIX chances to win CASH From 100 to 20000 poun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>URGENT You have won a 1 week FREE membership i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>XXXMobileMovieClub To use your credit click th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>Oh kim watching here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>Eh u remember how 2 spell his name Yes i did H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thats the way u feel. Thats the way ...</td>\n",
       "      <td>Fine if thats the way u feel Thats the way i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>England v Macedonia  dont miss the goalsteam n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "      <td>Is that seriously how you spell his name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>I‘m going to try for 2 months ha ha only joking</td>\n",
       "      <td>I‘m going to try for 2 months ha ha only joking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>So ü pay first lar... Then when is da stock co...</td>\n",
       "      <td>So ü pay first lar Then when is da stock comin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "      <td>Ffffffffff Alright no way I can meet up with y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "      <td>Just forced myself to eat a slice Im really no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "      <td>Lol your always so convincing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "      <td>Did you catch the bus  Are you frying an egg  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "      <td>Im back amp were packing the car now Ill let y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "      <td>Ahhh Work I vaguely remember that What does it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wait that's still not all that clear, were you...</td>\n",
       "      <td>Wait thats still not all that clear were you n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeah he got in at 2 and was v apologetic. n ha...</td>\n",
       "      <td>Yeah he got in at 2 and was v apologetic n had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>K tell me anything about you.</td>\n",
       "      <td>K tell me anything about you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>For fear of fainting with the of all that hous...</td>\n",
       "      <td>For fear of fainting with the of all that hous...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                          Body_text  \\\n",
       "0    ham  I've been searching for the right words to tha...   \n",
       "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3    ham  Even my brother is not like to speak with me. ...   \n",
       "4    ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "5    ham  As per your request 'Melle Melle (Oru Minnamin...   \n",
       "6   spam  WINNER!! As a valued network customer you have...   \n",
       "7   spam  Had your mobile 11 months or more? U R entitle...   \n",
       "8    ham  I'm gonna be home soon and i don't want to tal...   \n",
       "9   spam  SIX chances to win CASH! From 100 to 20,000 po...   \n",
       "10  spam  URGENT! You have won a 1 week FREE membership ...   \n",
       "11  spam  XXXMobileMovieClub: To use your credit, click ...   \n",
       "12   ham                         Oh k...i'm watching here:)   \n",
       "13   ham  Eh u remember how 2 spell his name... Yes i di...   \n",
       "14   ham  Fine if thats the way u feel. Thats the way ...   \n",
       "15  spam  England v Macedonia - dont miss the goals/team...   \n",
       "16   ham          Is that seriously how you spell his name?   \n",
       "17   ham    I‘m going to try for 2 months ha ha only joking   \n",
       "18   ham  So ü pay first lar... Then when is da stock co...   \n",
       "19   ham  Aft i finish my lunch then i go str down lor. ...   \n",
       "20   ham  Ffffffffff. Alright no way I can meet up with ...   \n",
       "21   ham  Just forced myself to eat a slice. I'm really ...   \n",
       "22   ham                     Lol your always so convincing.   \n",
       "23   ham  Did you catch the bus ? Are you frying an egg ...   \n",
       "24   ham  I'm back &amp; we're packing the car now, I'll...   \n",
       "25   ham  Ahhh. Work. I vaguely remember that! What does...   \n",
       "26   ham  Wait that's still not all that clear, were you...   \n",
       "27   ham  Yeah he got in at 2 and was v apologetic. n ha...   \n",
       "28   ham                      K tell me anything about you.   \n",
       "29   ham  For fear of fainting with the of all that hous...   \n",
       "\n",
       "                                      Body_text_clean  \n",
       "0   Ive been searching for the right words to than...  \n",
       "1   Free entry in 2 a wkly comp to win FA Cup fina...  \n",
       "2   Nah I dont think he goes to usf he lives aroun...  \n",
       "3   Even my brother is not like to speak with me T...  \n",
       "4                   I HAVE A DATE ON SUNDAY WITH WILL  \n",
       "5   As per your request Melle Melle Oru Minnaminun...  \n",
       "6   WINNER As a valued network customer you have b...  \n",
       "7   Had your mobile 11 months or more U R entitled...  \n",
       "8   Im gonna be home soon and i dont want to talk ...  \n",
       "9   SIX chances to win CASH From 100 to 20000 poun...  \n",
       "10  URGENT You have won a 1 week FREE membership i...  \n",
       "11  XXXMobileMovieClub To use your credit click th...  \n",
       "12                               Oh kim watching here  \n",
       "13  Eh u remember how 2 spell his name Yes i did H...  \n",
       "14  Fine if thats the way u feel Thats the way i...  \n",
       "15  England v Macedonia  dont miss the goalsteam n...  \n",
       "16           Is that seriously how you spell his name  \n",
       "17    I‘m going to try for 2 months ha ha only joking  \n",
       "18     So ü pay first lar Then when is da stock comin  \n",
       "19  Aft i finish my lunch then i go str down lor A...  \n",
       "20  Ffffffffff Alright no way I can meet up with y...  \n",
       "21  Just forced myself to eat a slice Im really no...  \n",
       "22                      Lol your always so convincing  \n",
       "23  Did you catch the bus  Are you frying an egg  ...  \n",
       "24  Im back amp were packing the car now Ill let y...  \n",
       "25  Ahhh Work I vaguely remember that What does it...  \n",
       "26  Wait thats still not all that clear were you n...  \n",
       "27  Yeah he got in at 2 and was v apologetic n had...  \n",
       "28                       K tell me anything about you  \n",
       "29  For fear of fainting with the of all that hous...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "\n",
    "\n",
    "dataset[\"Body_text_clean\"] = dataset['Body_text'].apply(lambda x:remove_punct(x))\n",
    "\n",
    "dataset.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed9345",
   "metadata": {},
   "source": [
    "Tokenization -> It is splitting same string or sentence into a list of words\n",
    "stopwords -> These are commonly used words that dont contribute much to the meaning of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b56b8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Body_text</th>\n",
       "      <th>Body_text_clean</th>\n",
       "      <th>body_text_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>Ive been searching for the right words to than...</td>\n",
       "      <td>[ive, been, searching, for, the, right, words,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>Even my brother is not like to speak with me T...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                          Body_text  \\\n",
       "0   ham  I've been searching for the right words to tha...   \n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3   ham  Even my brother is not like to speak with me. ...   \n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                     Body_text_clean  \\\n",
       "0  Ive been searching for the right words to than...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2  Nah I dont think he goes to usf he lives aroun...   \n",
       "3  Even my brother is not like to speak with me T...   \n",
       "4                  I HAVE A DATE ON SUNDAY WITH WILL   \n",
       "\n",
       "                                  body_text_tokenize  \n",
       "0  [ive, been, searching, for, the, right, words,...  \n",
       "1  [free, entry, in, 2, a, wkly, comp, to, win, f...  \n",
       "2  [nah, i, dont, think, he, goes, to, usf, he, l...  \n",
       "3  [even, my, brother, is, not, like, to, speak, ...  \n",
       "4         [i, have, a, date, on, sunday, with, will]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W',text)\n",
    "    return tokens\n",
    "\n",
    "dataset[\"body_text_tokenize\"] = dataset[\"Body_text_clean\"].apply(lambda x: tokenize(x.lower()))\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eacc68d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Body_text</th>\n",
       "      <th>Body_text_clean</th>\n",
       "      <th>body_text_tokenize</th>\n",
       "      <th>body_text_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>Ive been searching for the right words to than...</td>\n",
       "      <td>[ive, been, searching, for, the, right, words,...</td>\n",
       "      <td>[ive, searching, right, words, thank, breather...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>Even my brother is not like to speak with me T...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                          Body_text  \\\n",
       "0   ham  I've been searching for the right words to tha...   \n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3   ham  Even my brother is not like to speak with me. ...   \n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                     Body_text_clean  \\\n",
       "0  Ive been searching for the right words to than...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2  Nah I dont think he goes to usf he lives aroun...   \n",
       "3  Even my brother is not like to speak with me T...   \n",
       "4                  I HAVE A DATE ON SUNDAY WITH WILL   \n",
       "\n",
       "                                  body_text_tokenize  \\\n",
       "0  [ive, been, searching, for, the, right, words,...   \n",
       "1  [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "2  [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "3  [even, my, brother, is, not, like, to, speak, ...   \n",
       "4         [i, have, a, date, on, sunday, with, will]   \n",
       "\n",
       "                                    body_text_nostop  \n",
       "0  [ive, searching, right, words, thank, breather...  \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "2  [nah, dont, think, goes, usf, lives, around, t...  \n",
       "3  [even, brother, like, speak, treat, like, aids...  \n",
       "4                                     [date, sunday]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "def remove_stopwords(tokenize_list):\n",
    "    text = [text for text in tokenize_list if text not in stopwords]\n",
    "    return text\n",
    "\n",
    "dataset['body_text_nostop'] = dataset['body_text_tokenize'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856e6f10",
   "metadata": {},
   "source": [
    "Stemming is the process of reducing inflected or derived words to their words stem. More simply the process of stemming means often crudely chipping off the end of a word to leave only the base. So this means taking words with various suffixes and condensing them under the same root word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fa78a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Body_text</th>\n",
       "      <th>Body_text_clean</th>\n",
       "      <th>body_text_tokenize</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>Ive been searching for the right words to than...</td>\n",
       "      <td>[ive, been, searching, for, the, right, words,...</td>\n",
       "      <td>[ive, searching, right, words, thank, breather...</td>\n",
       "      <td>[ive, search, right, word, thank, breather, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>Even my brother is not like to speak with me T...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                          Body_text  \\\n",
       "0   ham  I've been searching for the right words to tha...   \n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3   ham  Even my brother is not like to speak with me. ...   \n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                     Body_text_clean  \\\n",
       "0  Ive been searching for the right words to than...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2  Nah I dont think he goes to usf he lives aroun...   \n",
       "3  Even my brother is not like to speak with me T...   \n",
       "4                  I HAVE A DATE ON SUNDAY WITH WILL   \n",
       "\n",
       "                                  body_text_tokenize  \\\n",
       "0  [ive, been, searching, for, the, right, words,...   \n",
       "1  [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "2  [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "3  [even, my, brother, is, not, like, to, speak, ...   \n",
       "4         [i, have, a, date, on, sunday, with, will]   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [ive, searching, right, words, thank, breather...   \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "2  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "3  [even, brother, like, speak, treat, like, aids...   \n",
       "4                                     [date, sunday]   \n",
       "\n",
       "                                   body_text_stemmed  \n",
       "0  [ive, search, right, word, thank, breather, pr...  \n",
       "1  [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
       "2  [nah, dont, think, goe, usf, live, around, tho...  \n",
       "3  [even, brother, like, speak, treat, like, aid,...  \n",
       "4                                     [date, sunday]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(tokenized_text):\n",
    "    text =  [ps.stem(word) for word in tokenized_text]\n",
    "    return text\n",
    "dataset[\"body_text_stemmed\"] = dataset[\"body_text_nostop\"].apply(lambda x:stemming(x))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6401ea2",
   "metadata": {},
   "source": [
    "Lemmatizing: It is the process of grouping together inflected parts of a word so they can be analysed as a single term, identified by the word's lemma. The Lemma is the canonical form of a set of words. For instance, type and typing would all be forms of the same Lemma. More simply , lemmatizing is using vocabulary analysis of words to remove inlfectional endings and return to the dictionary form of a words.Example type and typing would all be simplified to word type, because thats the root word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f56de42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Body_text</th>\n",
       "      <th>Body_text_clean</th>\n",
       "      <th>body_text_tokenize</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_stemmed</th>\n",
       "      <th>body_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>Ive been searching for the right words to than...</td>\n",
       "      <td>[ive, been, searching, for, the, right, words,...</td>\n",
       "      <td>[ive, searching, right, words, thank, breather...</td>\n",
       "      <td>[ive, search, right, word, thank, breather, pr...</td>\n",
       "      <td>[ive, searching, right, word, thank, breather,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>Even my brother is not like to speak with me T...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aid,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                          Body_text  \\\n",
       "0   ham  I've been searching for the right words to tha...   \n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3   ham  Even my brother is not like to speak with me. ...   \n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                     Body_text_clean  \\\n",
       "0  Ive been searching for the right words to than...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2  Nah I dont think he goes to usf he lives aroun...   \n",
       "3  Even my brother is not like to speak with me T...   \n",
       "4                  I HAVE A DATE ON SUNDAY WITH WILL   \n",
       "\n",
       "                                  body_text_tokenize  \\\n",
       "0  [ive, been, searching, for, the, right, words,...   \n",
       "1  [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "2  [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "3  [even, my, brother, is, not, like, to, speak, ...   \n",
       "4         [i, have, a, date, on, sunday, with, will]   \n",
       "\n",
       "                                    body_text_nostop  \\\n",
       "0  [ive, searching, right, words, thank, breather...   \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "2  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "3  [even, brother, like, speak, treat, like, aids...   \n",
       "4                                     [date, sunday]   \n",
       "\n",
       "                                   body_text_stemmed  \\\n",
       "0  [ive, search, right, word, thank, breather, pr...   \n",
       "1  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "2  [nah, dont, think, goe, usf, live, around, tho...   \n",
       "3  [even, brother, like, speak, treat, like, aid,...   \n",
       "4                                     [date, sunday]   \n",
       "\n",
       "                                body_text_lemmatized  \n",
       "0  [ive, searching, right, word, thank, breather,...  \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "2  [nah, dont, think, go, usf, life, around, though]  \n",
       "3  [even, brother, like, speak, treat, like, aid,...  \n",
       "4                                     [date, sunday]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "dataset[\"body_text_lemmatized\"] = dataset[\"body_text_nostop\"].apply(lambda x:lemmatizing(x))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad27ccc",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d8860",
   "metadata": {},
   "source": [
    "Now that we have learned how to clean up text data we will be using to build the ML model.The process that we use to convert text to a form that python and a ML algo can understand is called vectorising.\n",
    "\n",
    "This is defined process of coding text as integers to create feature vectors. A feature vector is an n-dimensional vector of numerical features that represent some object. So in our context that means we will be taking an individual text message and converting it to a numeric vector that represents the text message\n",
    "    \n",
    "Count Vectorization: This creates a document- term matrix where the entry of each cell will be a count of the number of times the word has occured in that document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c65a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cout_vect = CountVectorizer(analyzer=yzer = clean_text)\n",
    "x_counts = count.vect.fit(dataset[\"body\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
